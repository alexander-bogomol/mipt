RL for seq2seq practice:
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/girafe-ai/ml-mipt/blob/advanced_s21/week1_11_RL_outside_games/week11_RL_for_seq2sec.ipynb)

Further readings:

- Actually proving the policy gradient for discounted rewards -
  [article](https://papers.nips.cc/paper/1713-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf)
- On variance of policy gradient and optimal baselines:
  [article](https://papers.nips.cc/paper/4264-analysis-and-improvement-of-policy-gradient-estimation.pdf),
  another [article](https://arxiv.org/pdf/1301.2315.pdf)

_Based on
[Practical_RL week07](https://github.com/yandexdataschool/Practical_RL/tree/master/week07_seq2seq)_
